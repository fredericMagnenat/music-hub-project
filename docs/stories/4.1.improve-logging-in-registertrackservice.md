
# Story 4.1: Improve Logging in RegisterTrackService

---

- **Status**: Draft

---

## Story

**As a** Developer,
**I want** to refactor the logging in `RegisterTrackService` to include correlation IDs, structured context, and performance metrics,
**so that** it aligns with the project's logging best practices, improving traceability and observability.

---

## Acceptance Criteria

1.  All log statements produced by `RegisterTrackService` for a single request flow must include the same unique `correlation_id`.
2.  Key business event logs (e.g., track registration, event publishing) must contain a structured `business_context` field with relevant data like `isrc`, `producer_code`, and `operation`.
3.  The total execution time of the `registerTrack` method is logged at the `INFO` level upon completion.
4.  The execution time for the external API call to `musicPlatformPort.getTrackByIsrc` is logged.
5.  Log levels are reviewed and adjusted to ensure essential business flow information is logged at `INFO` level, while more granular details remain at `DEBUG` or `TRACE`.
6.  Integration tests must verify that log outputs are structured JSON and contain the required correlation and business context fields.

---

## Tasks / Subtasks

- [ ] **Task 1: Integrate Correlation ID** (AC: 1, 6)
    - [ ] Subtask 1.1: Add a `correlationId` parameter to the `registerTrack` method in the `RegisterTrackUseCase` interface and its implementation in `RegisterTrackService`.
    - [ ] Subtask 1.2: Propagate the `correlationId` to the private methods `fetchTrackMetadata` and `publishTrackWasRegisteredEvent`.
    - [ ] Subtask 1.3: Update all SLF4J log statements within `RegisterTrackService` to include the `correlationId`.

- [ ] **Task 2: Implement Structured & Performance Logging** (AC: 2, 3, 4, 6)
    - [ ] Subtask 2.1: Use structured logging patterns (e.g., key-value pairs or MDC) to add a `business_context` map to key `INFO` level logs.
    - [ ] Subtask 2.2: Implement timing logic at the beginning and end of the `registerTrack` method to calculate and log the total execution time.
    - [ ] Subtask 2.3: Add timing logs around the `musicPlatformPort.getTrackByIsrc` call to measure its specific duration.

- [ ] **Task 3: Review and Refactor Log Levels** (AC: 5)
    - [ ] Subtask 3.1: Analyze existing `DEBUG` logs and promote those critical for understanding the business flow to the `INFO` level.
    - [ ] Subtask 3.2: Ensure that detailed technical data, not essential for standard production monitoring, remains at `DEBUG` or `TRACE` levels.

- [ ] **Task 4: Update and Verify Tests** (AC: 6)
    - [ ] Subtask 4.1: Create or update an integration test to capture log output.
    - [ ] Subtask 4.2: In the test, assert that the captured log output is valid JSON.
    - [ ] Subtask 4.3: Assert that the JSON logs contain the `correlation_id` and `business_context` fields with expected values.
    - [ ] Subtask 4.4: Ensure all existing tests for `RegisterTrackService` continue to pass.

---

## Dev Notes

This story requires implementing logging patterns defined in the project's architecture.

*Source: `docs/architecture/logging-best-practices.md`*

### Key Architectural Guidelines

- **Structured Logging**: All new logs should be structured as JSON. The goal is to produce logs like the following example:
  ```json
  {
    "timestamp": "2024-01-15T10:30:00.123Z",
    "level": "INFO",
    "logger": "com.musichub.producer.application.service.RegisterTrackService",
    "message": "Track successfully registered",
    "correlation_id": "req-123-456",
    "business_context": {
      "producer_code": "FRLA1",
      "isrc": "FRLA12400001",
      "operation": "track_registration"
    }
  }
  ```

- **Correlation IDs**: A `correlation_id` must be passed through the request flow and included in every log statement to allow for easy tracing.

- **Exception Handling**: Adhere strictly to the "Either log OR rethrow" pattern. Since `RegisterTrackService` is in the **Application Layer**, it may log an exception and then rethrow it for the REST adapter layer to handle and convert into an HTTP response.

### Testing

- **Test Objective**: The primary goal is to verify the *structure and content* of the logs, not just the application's functionality.
- **Test Strategy**: An integration test (`@QuarkusTest`) is required. You will need to configure a test appender to capture the log output in memory.
- **Verification Steps**:
  1.  Invoke the `registerTrack` endpoint.
  2.  Capture the logged output.
  3.  Parse the JSON log strings.
  4.  Assert that the `correlation_id` is present and consistent across all logs for the request.
  5.  Assert that the `business_context` field exists and contains the correct data in the relevant logs.
  6.  Assert that the performance metrics (execution times) are logged as expected.

---

## Change Log

| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2025-09-13 | 1.0 | Initial draft of the story. | Bob (Scrum Master) |
